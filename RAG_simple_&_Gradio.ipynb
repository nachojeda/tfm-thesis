{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative AI PDF information exctractor\n",
    "In this use case it is shown how to exctract information from a PDF file through LLM queries. For this use case is necessary the use of a vector database (in this case FAISS), embeddings and OpenAI model calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"apis.env\")\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_path = \"TM6_digital_manual_MES-es-ES_prefill_20190121.pdf\"\n",
    "pdf_path = \"BOE-A-1978-31229-consolidado.pdf\"\n",
    "\n",
    "# Load pdf with external info not seen during training of the LLM\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Constitución Española.\\nCortes Generales\\n«BOE» núm. 311, de 29 de diciembre de 1978\\nReferencia: BOE-A-1978-31229\\nÍNDICE\\n   \\nPreámbulo ................................................................ 3\\nTÍTULO PRELIMINAR ........................................................... 3\\nTÍTULO I. De los derechos y deberes fundamentales ........................................ 4\\nCAPÍTULO PRIMERO. De los españoles y los extranjeros ................................... 5\\nCAPÍTULO SEGUNDO. Derechos y libertades .......................................... 5\\nSección 1.ª De los derechos fundamentales y de las libertades públicas ........................ 5\\nSección 2.ª De los derechos y deberes de los ciudadanos ................................. 8\\nCAPÍTULO TERCERO. De los principios rectores de la política social y económica ................... 10\\nCAPÍTULO CUARTO. De las garantías de las libertades y derechos fundamentales .................. 12\\nCAPÍTULO QUINTO. De la suspensión de los derechos y libertades ............................ 12\\nTÍTULO II. De la Corona .......................................................... 12\\nTÍTULO III. De las Cortes Generales .................................................. 14\\nCAPÍTULO PRIMERO. De las Cámaras .............................................. 14\\nCAPÍTULO SEGUNDO. De la elaboración de las leyes ..................................... 17\\nCAPÍTULO TERCERO. De los Tratados Internacionales .................................... 19\\nTÍTULO IV. Del Gobierno y de la Administración ........................................... 20\\nTÍTULO V. De las relaciones entre el Gobierno y las Cortes Generales ............................ 22\\nTÍTULO VI. Del Poder Judicial ...................................................... 24\\nTÍTULO VII. Economía y Hacienda ................................................... 25\\nLEGISLACIÓN CONSOLIDADA\\nPágina 1', metadata={'source': 'BOE-A-1978-31229-consolidado.pdf', 'page': 0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vector space representation with words from the external data\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# import transformers\n",
    "# embeddings = HuggingFaceEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings in vector database\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(pages, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use information retrieval from embedding for answer\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "model_name=\"gpt-3.5-turbo-instruct\"\n",
    "temperature=0\n",
    "max_tokens=16\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name=model_name,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens\n",
    "    )\n",
    "chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': ' Sí, se puede utilizar el modo \"Turbo\" para triturar alimentos'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"Existe algún modo rápido para triturar alimentos?\"\n",
    "chain(input, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add UI with Gradio\n",
    "At this point I'll add a UI provided by Gradio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nacho\\anaconda3\\envs\\TFM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def model_hyperparameters(temperature, max_tokens):#\n",
    "    llm = OpenAI(\n",
    "        model_name=\"gpt-3.5-turbo-instruct\",\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "        )\n",
    "    chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever())\n",
    "    return chain\n",
    "\n",
    "def generate(input, temperature, max_tokens): #, temperature, max_tokens\n",
    "    # output = client.generate(input, max_new_tokens=slider).generated_text\n",
    "    chain = model_hyperparameters(temperature, max_tokens)\n",
    "    output = chain(input, return_only_outputs=True)\n",
    "    return output\n",
    "\n",
    "demo = gr.Interface(fn=generate, \n",
    "                    inputs=[gr.Textbox(label=\"Prompt\"),\n",
    "                            gr.Slider(label=\"Temperature\", \n",
    "                                      value=0.1,  \n",
    "                                      maximum=1, \n",
    "                                      minimum=0.1),\n",
    "                            gr.Slider(label=\"Max tokens\", \n",
    "                                      value=16,  \n",
    "                                      maximum=64, \n",
    "                                      minimum=8)],\n",
    "                    outputs=[gr.Textbox(label=\"Completion\")])\n",
    "\n",
    "demo.launch(share=True) #server_port=int(os.environ['PORT1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7864\n",
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7863\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
