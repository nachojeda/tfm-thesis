{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG app TFM v4\n",
    "In this use case it is shown how to extract information from a PDF file through LLM queries with RAG (Retrieval Augmented Generation) technology. For this use case is necessary the use of a vector database (in this case FAISS), embeddings and OpenAI model calls. To show the final result, the model is embedded on a Gradio UI. In this version it would be used Llama Index as vector databse.\n",
    "\n",
    "In this notebook, it will be conducted an evaluation on the v4 version of the RAG system. This evaluation will consist on evaluating the following concepts:\n",
    "\n",
    "* Answer relevance\n",
    "* Context Relevance\n",
    "* Groundedness\n",
    "\n",
    "For this evaluation a set of evaluation questions is made in order to make the system in line with several possible reasons that cover different topics a RAG system should cover in order to function correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evalutation using Llama Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index import Document\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "\n",
    "load_dotenv(\"apis.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the main theme or topic of this document?\n",
      "Can you summarize the key points made in this document?\n",
      "What are the primary arguments or claims presented?\n",
      "Are there any notable facts or figures mentioned? If so, what are they?\n",
      "Can you provide an example or case study mentioned in the document?\n",
      "What conclusions are drawn in this document?\n",
      "Are there any contradictions or points of debate within the document?\n",
      "What background or contextual information is provided?\n",
      "What are the limitations or gaps identified in the document?\n",
      "What recommendations or next steps does the document propose?\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = \"./attention-is-all-you-need.pdf\"\n",
    "\n",
    "temperature = 0.1\n",
    "max_tokens = 512\n",
    "\n",
    "def evaluation_responses(pdf, temperature=0.2, max_tokens=128):\n",
    "    documents = SimpleDirectoryReader(\n",
    "        input_files=[pdf]\n",
    "    ).load_data()\n",
    "    document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "    embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\", embed_batch_size=10)\n",
    "\n",
    "    llm = OpenAI(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        streaming=True)\n",
    "    \n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        llm=llm, embed_model=embed_model\n",
    "    )\n",
    "    index = VectorStoreIndex.from_documents([document],\n",
    "                                        service_context=service_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "    return query_engine\n",
    "\n",
    "query_engine = evaluation_responses(pdf, temperature=temperature, max_tokens=max_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "# from utils import get_prebuilt_trulens_recorder\n",
    "from trulens_eval import (\n",
    "    Feedback,\n",
    "    TruLlama,\n",
    "    OpenAI\n",
    ")\n",
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "qa_relevance = (\n",
    "    Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "\n",
    "qs_relevance = (\n",
    "    Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(TruLlama.select_source_nodes().node.text)\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "# grounded = Groundedness(groundedness_provider=openai, summarize_provider=openai)\n",
    "grounded = Groundedness(groundedness_provider=openai)\n",
    "\n",
    "groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "        .on(TruLlama.select_source_nodes().node.text)\n",
    "        .on_output()\n",
    "        .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "feedbacks = [qa_relevance, qs_relevance, groundedness]\n",
    "\n",
    "def get_prebuilt_trulens_recorder(query_engine, app_id):\n",
    "    tru_recorder = TruLlama(\n",
    "        query_engine,\n",
    "        app_id=app_id,\n",
    "        feedbacks=feedbacks\n",
    "        )\n",
    "    return tru_recorder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic RAG Pipeline\n",
    "tru_recorder = get_prebuilt_trulens_recorder(query_engine,\n",
    "                                             app_id=\"Basic RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅What is the main theme or topic of this document?\n",
      "✅Can you summarize the key points made in this document?\n",
      "✅What are the primary arguments or claims presented?\n",
      "✅Are there any notable facts or figures mentioned? If so, what are they?\n",
      "✅Can you provide an example or case study mentioned in the document?\n",
      "✅What conclusions are drawn in this document?\n",
      "✅Are there any contradictions or points of debate within the document?\n",
      "✅What background or contextual information is provided?\n",
      "✅What are the limitations or gaps identified in the document?\n",
      "✅What recommendations or next steps does the document propose?\n"
     ]
    }
   ],
   "source": [
    "emo = \"\\U00002705\"\n",
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)\n",
    "        print(emo+question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_7edff4658b1d94d08a72006bcb9ad23b</td>\n",
       "      <td>\"What is the main theme or topic of this docum...</td>\n",
       "      <td>\"\\nThe main theme or topic of this document is...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_7edff4658b1d94d08a7...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:27:49.895158\", \"...</td>\n",
       "      <td>2024-01-14T18:27:56.168035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': 'What is the main theme o...</td>\n",
       "      <td>[{'args': {'prompt': 'What is the main theme o...</td>\n",
       "      <td>[{'args': {'source': 'For translation tasks, t...</td>\n",
       "      <td>6</td>\n",
       "      <td>2039</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_688549a64c6878e79a1cb75508b4643f</td>\n",
       "      <td>\"Can you summarize the key points made in this...</td>\n",
       "      <td>\"\\nThe document discusses the Transformer, a s...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_688549a64c6878e79a1...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:27:56.854509\", \"...</td>\n",
       "      <td>2024-01-14T18:28:03.515761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[{'args': {'prompt': 'Can you summarize the ke...</td>\n",
       "      <td>[{'args': {'prompt': 'Can you summarize the ke...</td>\n",
       "      <td>[{'args': {'source': 'Table 2 summarizes our r...</td>\n",
       "      <td>6</td>\n",
       "      <td>2093</td>\n",
       "      <td>0.003159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_681fecec01ba72f3f97c55946f53036f</td>\n",
       "      <td>\"What are the primary arguments or claims pres...</td>\n",
       "      <td>\"\\nThe primary arguments or claims presented a...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_681fecec01ba72f3f97...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:28:04.197017\", \"...</td>\n",
       "      <td>2024-01-14T18:28:10.476767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': 'What are the primary arg...</td>\n",
       "      <td>[{'args': {'prompt': 'What are the primary arg...</td>\n",
       "      <td>[{'args': {'source': 'Table 2 summarizes our r...</td>\n",
       "      <td>6</td>\n",
       "      <td>2092</td>\n",
       "      <td>0.003162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_715031da3db5ea248ced50097836c18f</td>\n",
       "      <td>\"Are there any notable facts or figures mentio...</td>\n",
       "      <td>\"\\nYes, there are several notable facts and fi...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_715031da3db5ea248ce...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:28:11.134134\", \"...</td>\n",
       "      <td>2024-01-14T18:28:17.329805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[{'args': {'prompt': 'Are there any notable fa...</td>\n",
       "      <td>[{'args': {'prompt': 'Are there any notable fa...</td>\n",
       "      <td>[{'args': {'source': 'Table 2 summarizes our r...</td>\n",
       "      <td>6</td>\n",
       "      <td>2103</td>\n",
       "      <td>0.003169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_f6fcd18ca17a6f7bbf895ce9a2456eb8</td>\n",
       "      <td>\"Can you provide an example or case study ment...</td>\n",
       "      <td>\"On both WMT 2014 English-to-German and WMT 20...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_f6fcd18ca17a6f7bbf8...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:28:18.247210\", \"...</td>\n",
       "      <td>2024-01-14T18:28:24.008119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': 'Can you provide an examp...</td>\n",
       "      <td>[{'args': {'prompt': 'Can you provide an examp...</td>\n",
       "      <td>[{'args': {'source': '[12] Sepp Hochreiter and...</td>\n",
       "      <td>5</td>\n",
       "      <td>2026</td>\n",
       "      <td>0.003042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_c1a51b17711ecbd725ac37858e654bbd</td>\n",
       "      <td>\"What conclusions are drawn in this document?\"</td>\n",
       "      <td>\"\\nThe document concludes that the Transformer...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_c1a51b17711ecbd725a...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:28:24.763494\", \"...</td>\n",
       "      <td>2024-01-14T18:28:30.659220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': 'What conclusions are dra...</td>\n",
       "      <td>[{'args': {'prompt': 'What conclusions are dra...</td>\n",
       "      <td>[{'args': {'source': 'Table 2 summarizes our r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2074</td>\n",
       "      <td>0.003129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_037a06e283717c38d18e3e62778ec0b9</td>\n",
       "      <td>\"Are there any contradictions or points of deb...</td>\n",
       "      <td>\"\\nNo, there are no contradictions or points o...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_037a06e283717c38d18...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:28:31.443113\", \"...</td>\n",
       "      <td>2024-01-14T18:28:36.970158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[{'args': {'prompt': 'Are there any contradict...</td>\n",
       "      <td>[{'args': {'prompt': 'Are there any contradict...</td>\n",
       "      <td>[{'args': {'source': 'Table 2 summarizes our r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2061</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_56ea9e7797aff13d79b176dd5172ae09</td>\n",
       "      <td>\"What background or contextual information is ...</td>\n",
       "      <td>\"\\nThe context information provided includes r...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_56ea9e7797aff13d79b...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:28:37.635462\", \"...</td>\n",
       "      <td>2024-01-14T18:28:43.634359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>[{'args': {'prompt': 'What background or conte...</td>\n",
       "      <td>[{'args': {'prompt': 'What background or conte...</td>\n",
       "      <td>[{'args': {'source': '[12] Sepp Hochreiter and...</td>\n",
       "      <td>5</td>\n",
       "      <td>2026</td>\n",
       "      <td>0.003054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_8e5d3ae224e3f96b1b08dd98d1b6f7f1</td>\n",
       "      <td>\"What are the limitations or gaps identified i...</td>\n",
       "      <td>\"\\nThe document does not mention any specific ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_8e5d3ae224e3f96b1b0...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:28:44.251324\", \"...</td>\n",
       "      <td>2024-01-14T18:28:49.715763</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[{'args': {'prompt': 'What are the limitations...</td>\n",
       "      <td>[{'args': {'prompt': 'What are the limitations...</td>\n",
       "      <td>[{'args': {'source': 'Table 2 summarizes our r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2054</td>\n",
       "      <td>0.003081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Basic RAG</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_aad48c2926fd98401b712c9345fe1eed</td>\n",
       "      <td>\"What recommendations or next steps does the d...</td>\n",
       "      <td>\"We plan to extend the Transformer to problems...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_aad48c2926fd98401b7...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-14T18:28:50.536315\", \"...</td>\n",
       "      <td>2024-01-14T18:28:56.220076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': 'What recommendations or ...</td>\n",
       "      <td>[{'args': {'prompt': 'What recommendations or ...</td>\n",
       "      <td>[{'args': {'source': 'For translation tasks, t...</td>\n",
       "      <td>5</td>\n",
       "      <td>2053</td>\n",
       "      <td>0.003090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id                                           app_json  \\\n",
       "0  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "5  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "6  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "7  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "8  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "9  Basic RAG  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "5  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "6  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "7  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "8  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "9  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_7edff4658b1d94d08a72006bcb9ad23b   \n",
       "1  record_hash_688549a64c6878e79a1cb75508b4643f   \n",
       "2  record_hash_681fecec01ba72f3f97c55946f53036f   \n",
       "3  record_hash_715031da3db5ea248ced50097836c18f   \n",
       "4  record_hash_f6fcd18ca17a6f7bbf895ce9a2456eb8   \n",
       "5  record_hash_c1a51b17711ecbd725ac37858e654bbd   \n",
       "6  record_hash_037a06e283717c38d18e3e62778ec0b9   \n",
       "7  record_hash_56ea9e7797aff13d79b176dd5172ae09   \n",
       "8  record_hash_8e5d3ae224e3f96b1b08dd98d1b6f7f1   \n",
       "9  record_hash_aad48c2926fd98401b712c9345fe1eed   \n",
       "\n",
       "                                               input  \\\n",
       "0  \"What is the main theme or topic of this docum...   \n",
       "1  \"Can you summarize the key points made in this...   \n",
       "2  \"What are the primary arguments or claims pres...   \n",
       "3  \"Are there any notable facts or figures mentio...   \n",
       "4  \"Can you provide an example or case study ment...   \n",
       "5     \"What conclusions are drawn in this document?\"   \n",
       "6  \"Are there any contradictions or points of deb...   \n",
       "7  \"What background or contextual information is ...   \n",
       "8  \"What are the limitations or gaps identified i...   \n",
       "9  \"What recommendations or next steps does the d...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"\\nThe main theme or topic of this document is...    -   \n",
       "1  \"\\nThe document discusses the Transformer, a s...    -   \n",
       "2  \"\\nThe primary arguments or claims presented a...    -   \n",
       "3  \"\\nYes, there are several notable facts and fi...    -   \n",
       "4  \"On both WMT 2014 English-to-German and WMT 20...    -   \n",
       "5  \"\\nThe document concludes that the Transformer...    -   \n",
       "6  \"\\nNo, there are no contradictions or points o...    -   \n",
       "7  \"\\nThe context information provided includes r...    -   \n",
       "8  \"\\nThe document does not mention any specific ...    -   \n",
       "9  \"We plan to extend the Transformer to problems...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_7edff4658b1d94d08a7...   \n",
       "1  {\"record_id\": \"record_hash_688549a64c6878e79a1...   \n",
       "2  {\"record_id\": \"record_hash_681fecec01ba72f3f97...   \n",
       "3  {\"record_id\": \"record_hash_715031da3db5ea248ce...   \n",
       "4  {\"record_id\": \"record_hash_f6fcd18ca17a6f7bbf8...   \n",
       "5  {\"record_id\": \"record_hash_c1a51b17711ecbd725a...   \n",
       "6  {\"record_id\": \"record_hash_037a06e283717c38d18...   \n",
       "7  {\"record_id\": \"record_hash_56ea9e7797aff13d79b...   \n",
       "8  {\"record_id\": \"record_hash_8e5d3ae224e3f96b1b0...   \n",
       "9  {\"record_id\": \"record_hash_aad48c2926fd98401b7...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "1  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "2  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "3  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "4  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "5  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "6  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "7  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "8  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "9  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-01-14T18:27:49.895158\", \"...   \n",
       "1  {\"start_time\": \"2024-01-14T18:27:56.854509\", \"...   \n",
       "2  {\"start_time\": \"2024-01-14T18:28:04.197017\", \"...   \n",
       "3  {\"start_time\": \"2024-01-14T18:28:11.134134\", \"...   \n",
       "4  {\"start_time\": \"2024-01-14T18:28:18.247210\", \"...   \n",
       "5  {\"start_time\": \"2024-01-14T18:28:24.763494\", \"...   \n",
       "6  {\"start_time\": \"2024-01-14T18:28:31.443113\", \"...   \n",
       "7  {\"start_time\": \"2024-01-14T18:28:37.635462\", \"...   \n",
       "8  {\"start_time\": \"2024-01-14T18:28:44.251324\", \"...   \n",
       "9  {\"start_time\": \"2024-01-14T18:28:50.536315\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-01-14T18:27:56.168035               1.0               0.50   \n",
       "1  2024-01-14T18:28:03.515761               1.0               0.50   \n",
       "2  2024-01-14T18:28:10.476767               1.0               0.00   \n",
       "3  2024-01-14T18:28:17.329805               1.0               1.00   \n",
       "4  2024-01-14T18:28:24.008119               0.0               0.00   \n",
       "5  2024-01-14T18:28:30.659220               1.0               0.60   \n",
       "6  2024-01-14T18:28:36.970158               1.0               0.00   \n",
       "7  2024-01-14T18:28:43.634359               1.0               0.95   \n",
       "8  2024-01-14T18:28:49.715763               0.4               0.00   \n",
       "9  2024-01-14T18:28:56.220076               1.0               0.10   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0      1.000000  [{'args': {'prompt': 'What is the main theme o...   \n",
       "1      0.800000  [{'args': {'prompt': 'Can you summarize the ke...   \n",
       "2      1.000000  [{'args': {'prompt': 'What are the primary arg...   \n",
       "3      0.833333  [{'args': {'prompt': 'Are there any notable fa...   \n",
       "4      1.000000  [{'args': {'prompt': 'Can you provide an examp...   \n",
       "5      1.000000  [{'args': {'prompt': 'What conclusions are dra...   \n",
       "6      0.000000  [{'args': {'prompt': 'Are there any contradict...   \n",
       "7      0.636364  [{'args': {'prompt': 'What background or conte...   \n",
       "8      0.500000  [{'args': {'prompt': 'What are the limitations...   \n",
       "9      1.000000  [{'args': {'prompt': 'What recommendations or ...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is the main theme o...   \n",
       "1  [{'args': {'prompt': 'Can you summarize the ke...   \n",
       "2  [{'args': {'prompt': 'What are the primary arg...   \n",
       "3  [{'args': {'prompt': 'Are there any notable fa...   \n",
       "4  [{'args': {'prompt': 'Can you provide an examp...   \n",
       "5  [{'args': {'prompt': 'What conclusions are dra...   \n",
       "6  [{'args': {'prompt': 'Are there any contradict...   \n",
       "7  [{'args': {'prompt': 'What background or conte...   \n",
       "8  [{'args': {'prompt': 'What are the limitations...   \n",
       "9  [{'args': {'prompt': 'What recommendations or ...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': 'For translation tasks, t...        6          2039   \n",
       "1  [{'args': {'source': 'Table 2 summarizes our r...        6          2093   \n",
       "2  [{'args': {'source': 'Table 2 summarizes our r...        6          2092   \n",
       "3  [{'args': {'source': 'Table 2 summarizes our r...        6          2103   \n",
       "4  [{'args': {'source': '[12] Sepp Hochreiter and...        5          2026   \n",
       "5  [{'args': {'source': 'Table 2 summarizes our r...        5          2074   \n",
       "6  [{'args': {'source': 'Table 2 summarizes our r...        5          2061   \n",
       "7  [{'args': {'source': '[12] Sepp Hochreiter and...        5          2026   \n",
       "8  [{'args': {'source': 'Table 2 summarizes our r...        5          2054   \n",
       "9  [{'args': {'source': 'For translation tasks, t...        5          2053   \n",
       "\n",
       "   total_cost  \n",
       "0    0.003070  \n",
       "1    0.003159  \n",
       "2    0.003162  \n",
       "3    0.003169  \n",
       "4    0.003042  \n",
       "5    0.003129  \n",
       "6    0.003095  \n",
       "7    0.003054  \n",
       "8    0.003081  \n",
       "9    0.003090  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7acd01a46e432a9eb168fc3c14ca1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a refined DataFrame with the 10 questions and their corresponding reasons\n",
    "refined_questions_and_reasons = pd.DataFrame({\n",
    "    \"Question\": [\n",
    "        \"What is the main theme or topic of this document?\",\n",
    "        \"Can you summarize the key points made in this document?\",\n",
    "        \"What are the primary arguments or claims presented?\",\n",
    "        \"Are there any notable facts or figures mentioned? If so, what are they?\",\n",
    "        \"Can you provide an example or case study mentioned in the document?\",\n",
    "        \"What conclusions are drawn in this document?\",\n",
    "        \"Are there any contradictions or points of debate within the document?\",\n",
    "        \"What background or contextual information is provided?\",\n",
    "        \"What are the limitations or gaps identified in the document?\",\n",
    "        \"What recommendations or next steps does the document propose?\"\n",
    "    ],\n",
    "    \"Reason\": [\n",
    "        \"Tests the system's ability to identify the central subject or theme.\",\n",
    "        \"Evaluates the system's summarization skills and understanding of major points.\",\n",
    "        \"Checks the system's ability to identify and articulate main arguments or claims.\",\n",
    "        \"Tests the system's ability to pick out and relay specific data points.\",\n",
    "        \"Evaluates how well the system can extract and present examples or case studies.\",\n",
    "        \"Tests understanding of the document’s conclusions or final thoughts.\",\n",
    "        \"Checks the system's ability to identify conflicting information or areas of contention.\",\n",
    "        \"Evaluates the system's recognition of context-setting information.\",\n",
    "        \"Assesses the system's ability to recognize acknowledged limitations or gaps.\",\n",
    "        \"Tests the system's comprehension of proposed future actions or recommendations.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "refined_questions_and_reasons.head(10)  # Displaying the DataFrame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
